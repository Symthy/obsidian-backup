
# SQL インデックスを向上させるための 3 つのルール

[# SQL index best practices for performance: 3 rules for better SQL indexes](https://www.cockroachlabs.com/blog/sql-performance-best-practices/?ref=dailydev)

良いインデックスとは  
- データを効率的にフィルターする（ルール１）
- データをソートする必要がなくなる（ルール２）
- インデックスにあるデータでクエリに答える（ルール３）

何が起こっているのかを確認するために、データベースの動作を可視化する必要がある → `EXPLAIN ANALYZE`
## ルール0: ステートメントプランを使って、データベースがクエリをどのように処理するかを確認する

EXPLAIN ANALYZEを前に付けてクエリを実行する

```sql
EXPLAIN ANALYZE SELECT title, body, sender, datetime 
                  FROM messages
                  WHERE email = 'person@example.com'
                  ORDER BY datetime DESC
                  LIMIT 10;
```

実行結果（ステートメント計画）：

- ステートメントプランは下から上に読み込まれる（下から見ていく必要がある）。
- （一番上の）クラスタに負荷がかかっているかどうか、どのような負荷か、結果のどれだけがすでにメモリにあるかなど、コントロールできない多くの要因によって大きく変わる可能性があるため、信用してはいけない。
- 見るべきは、それ以外のすべて（top-k、filter、scan）

```
                                         info

- - -

  planning time: 683µs
  execution time: 3s
  distribution: local
  vectorized: true
  rows read from KV: 1,000,000 (226 MiB)
  cumulative time spent in KV: 3s
  maximum memory usage: 10 MiB
  network usage: 0 B (0 messages)

  • top-k
  │ nodes: n1
  │ actual row count: 10
  │ estimated max memory allocated: 10 KiB
  │ estimated max sql temp disk usage: 0 B
  │ estimated row count: 2
  │ order: -datetime
  │ k: 10
  │
  └── • filter
      │ nodes: n1
      │ actual row count: 1,000
      │ estimated row count: 2
      │ filter: email = 'person@example.com'
      │
      └── • scan
            nodes: n1
            actual row count: 1,000,000
            KV time: 3s
            KV contention time: 0µs
            KV rows read: 1,000,000
            KV bytes read: 226 MiB
            estimated max memory allocated: 10 MiB
            estimated row count: 1,000,000 (100% of the table; stats collected 6 seconds ago)
            table: messages@primary
            spans: FULL SCAN
(35 rows)

Time: 3.106s total (execution 2.991s / network 0.115s)
```

- このクエリには3つのステージがある
	- scan ステージ：テーブルをスキャンし、100万行すべてをロードする必要があったことを示している（`actual row count` 参照）。table: messages@messages_pkey という行からテーブルを見ていることがわかる。これらの100万行は filter ステージに渡される
	- filter ステージ：1000行に切り詰める。この1,000行が top-k ステージに渡される
	- top-k ステージ：1,000行をソートし、実際に欲しい10行を返す。

↓ もっといい方法
## ルール1：インデックスでクエリをフィルタリングする

- テーブルスキャンを避ける唯一の方法は、インデックスを作成すること
	- 最も簡単なものは、'email'フィールドの単一列インデックス
	- このインデックスはemail順に並べられ、サーバーはユーザーのメッセージだけを分離し、テーブル内の他の999,000件を無視することができる。  

```sql
CREATE INDEX email_idx ON messages (email);
```
  
インデックス作成後のステートメント計画：

```
                                      info
- - -

  planning time: 557µs
  execution time: 121ms
  distribution: local
  vectorized: true
  rows read from KV: 2,000 (280 KiB)
  cumulative time spent in KV: 120ms
  maximum memory usage: 1.1 MiB
  network usage: 0 B (0 messages)

  • top-k
  │ nodes: n1
  │ actual row count: 10
  │ estimated max memory allocated: 10 KiB
  │ estimated max sql temp disk usage: 0 B
  │ estimated row count: 2
  │ order: -datetime
  │ k: 10
  │
  └── • index join
      │ nodes: n1
      │ actual row count: 1,000
      │ KV time: 117ms
      │ KV contention time: 0µs
      │ KV rows read: 1,000
      │ KV bytes read: 211 KiB
      │ estimated max memory allocated: 960 KiB
      │ estimated max sql temp disk usage: 0 B
      │ estimated row count: 2
      │ table: messages@primary
      │
      └── • scan
            nodes: n1
            actual row count: 1,000
            KV time: 3ms
            KV contention time: 0µs
            KV rows read: 1,000
            KV bytes read: 69 KiB
            estimated max memory allocated: 120 KiB
            estimated row count: 2 (<0.01% of the table; stats collected 2 minutes ago)
            table: messages@email_idx
            spans: [/'person@example.com' - /'person@example.com']
(41 rows)

Time: 228ms total (execution 122ms / network 107ms)
```

まだ3つのステージがあるが、
- scan ステージ：100万行ではなく、1,000行にしか触れていない。table:messages@email_idxという行のインデックスを使用になった。
- 第2ステージが filter から、現在は index join です。なぜなら、データベースはインデックスの関連部分をスキャンすることから始め、すぐに datetime（インデックスにないフィールド）でソートする必要があることに気づいたため。  
- 「100万行をスキャンして99.9％を捨てる」から「1,000のインデックス・エントリーを検索し、必要な1,000行だけを検索」になった。最終段階のtop-k（データベースがソートを実行する）は以前とまったく同じ。

この段階を省くには、さらに優れたインデックスが必要になる。
## ルール2：インデックスを使ってクエリをソートする  

- ルール１で作成したインデックスは email 順に並ぶが、ソートが必要なタイムスタンプに関する情報を持っていない。
- より良いインデックスには、タイムスタンプの情報も含まれ、タイムスタンプでソートされるのが理想的で（両方のフィールドに複合インデックスを使う）  

```sql
CREATE INDEX email_datetime_idx ON messages (email, datetime)；  

# 古いインデックスは削除
DROP INDEX email_idx；  
```
  
ステートメント計画：

```
                                     info

- - -

  planning time: 796µs
  execution time: 6ms
  distribution: local
  vectorized: true
  rows read from KV: 20 (2.7 KiB)
  cumulative time spent in KV: 6ms
  maximum memory usage: 60 KiB
  network usage: 0 B (0 messages)

  • index join
  │ nodes: n1
  │ actual row count: 10
  │ KV time: 3ms
  │ KV contention time: 0µs
  │ KV rows read: 10
  │ KV bytes read: 1.9 KiB
  │ estimated max memory allocated: 30 KiB
  │ estimated max sql temp disk usage: 0 B
  │ estimated row count: 10
  │ table: messages@primary
  │
  └── • revscan
        nodes: n1
        actual row count: 10
        KV time: 2ms
        KV contention time: 0µs
        KV rows read: 10
        KV bytes read: 780 B
        estimated max memory allocated: 20 KiB
        estimated row count: 10 (<0.01% of the table; stats collected 43 seconds ago)
        table: messages@email_datetime_idx
        spans: [/'person@example.com' - /'person@example.com']
        limit: 10
(33 rows)

Time: 92ms total (execution 8ms / network 84ms)

```

- ステージが2つしかなくなった
	- 一番下のステージ（revscan）は、クラスタがインデックスの領域を逆順にスキャンしていることを示す
		- テーブルの行は、作成したばかりのインデックスを使用していることを示している。
		- 実際の行数はわずか10行であることがわかる。
		- インデックスにアクセスして、このクエリに必要な10行だけを見つけることができた。
	- 最終段階はインデックス結合で、必要な10行のみを検索している。  
  
繰り返しますが、これは大きな改善です。最初のインデックスはEメールに関するもので、100万行のテーブルをスキャンし、Eメールでフィルタリングしてソートしていたのが、1,000のインデックスエントリをスキャンし、個別にテーブルを検索してソートするようになった。つまり、100万行のスキャンは、1,000のインデックス・エントリーのスキャンと1,000のルックアップ操作（結合）になり、テーブルの他の99.9％を見る必要がなくなったのです。現在では、10個のインデックスエントリをスキャンし、テーブルから10行を検索するだけです。インデックスが既にソートされているため）ソートする必要はありません。では、次のレベルに進んでみましょう。

## ルール3：インデックスでクエリをカバーする

```sql
EXPLAIN ANALYZE SELECT datetime FROM messages  
```

上記を実行すると revscan のみになる。データベースは必要な10個のインデックス・エントリーを見つけ、そのエントリーにクエリーに答えるのに必要なすべての情報が含まれていたため、テーブルに行くことなくクエリーを実行することができる。
→ Covered Query と呼ばれ、クエリーに答えるためにテーブルに触れる必要さえなくすことで、リードを最適化する鍵となる。  

実現するためのアプローチとして、
一つの解決策は、複合インデックスにさらにカラムを追加してインデックスを構築することだが、それは理想的なアプローチではない。
理想的なアプローチは、必要なデータをフィルタリングやソートに必要なインデックスキーと一緒に保存すること（＝STORING）。

```sql
CREATE INDEX email_datetime_storing_title_body_sender_idx 
         ON messages (email, datetime) 
         STORING (title, body, sender);   # postgresqlの場合は INCLUDE
```


```
                                  info
- - -
  planning time: 2ms
  execution time: 6ms
  distribution: local
  vectorized: true
  rows read from KV: 10 (2.1 KiB)
  cumulative time spent in KV: 5ms
  maximum memory usage: 20 KiB
  network usage: 0 B (0 messages)

  • revscan
    nodes: n1
    actual row count: 10
    KV time: 5ms
    KV contention time: 0µs
    KV rows read: 10
    KV bytes read: 2.1 KiB
    estimated max memory allocated: 20 KiB
    estimated row count: 2 (<0.01% of the table; stats collected 3 minutes ago)
    table: messages@email_datetime_storing_title_body_sender_idx
    spans: [/'person@example.com' - /'person@example.com']
    limit: 10
(21 rows)

Time: 88ms total (execution 9ms / network 79ms)
```

# これらのIndexのベスト・プラクティスに関する注意事項

- 第一に、インデックスはそのインデックスが指すテーブル行と同期していなければなりません。つまり、ある行への書き込みは、テーブルとインデックスの両方を参照しなければならない。そして、インデックスが最終的に一貫性を保つことを望まないため、トランザクションとそれに伴うオーバーヘッドが必要になります。そのため、テーブル上にあまり多くのインデックスを作らないようにしましょう。  
- 第二に、大きなフィールドにインデックスを付けると、大きなインデックスを持つことになる。  
- そして3つ目は、常にEXPLAIN計画を使用して、物事が期待通りに動いているかチェックすること



#SQL 
